python -c 'import theano; print(theano.config)' | less

To overwrite default config, create the following file:
    $home/.theanorc

- check the layer shape
    model.layers[...].input_shape
    model.layers[...].output_shape 
model.layers is only accessible once the model is instantiated.
use .keras_shape on the output instantiated layer to get the output shape of
your tensor
    
- output of intermediate layer

# METHOD 1 create a new model with the layers that you are interested in 
from keras.models import Model
model = ...
layer_name = 'my_layer'
intermediate_layer_model = Model(inputs=model.input, 
                                 outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predit(data)

# METHOD 2 build keras function return the output of ceterian layer given
# certain input 
from keras import backend as K
get_3rd_layer_output = K.function([model.layers[0].input],
                                   model.layers[3].output])
layer_output = get_3rd_layer_output([x])[0]


get_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()]
                                   model.layers[3].output])
# output in test mode=0
layer_output = get_3rd_layer_output([x, 0])[0]
# output in train mode=1
layer_output = get_3rd_layer_output([x, 1])[0]


# METHOD 3
model.summary()  # print all layers and their output shape


- LTSM
stateful: means the states from samples of each batch will be reused as
initial sates for the sample in the next batch


build complex graph: 
    - model is a collection of layers
    - model can be nested inside layers
    - concat will join layers togeter


build your own network layer
    - inherit from layers.Layer 
    - implement: compute_output_shape() 
    - call() input to generate output


numpy resources:
- numpy 100 exercises: 
    https://github.com/rougier/numpy-100/blob/master/100%20Numpy%20exercises.md
- numpy quick start    
    https://docs.scipy.org/doc/numpy-dev/user/quickstart.html
- numpy tutorial
    http://www.labri.fr/perso/nrougier/teaching/numpy/numpy.html
- numpy nd array indexing
    https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html

theano
    - numpy + symbolic math
    - decalre variable, build expr for the computation graph
    - use T.grad to compute gradient, jacobi, hessian (auto differentiation)
    - use shared, reduce, can to for recurrent net 
    - steps: 
        1. use theano.tensor (T) to define variables
        2. define expression with the variables 
        3. use theano.function to define the function to be compiled
        4. invoke the function
            6. use shared variable to modify state
            7. use scan to unroll loop compuation
            8. use normal python function as subgraph to compose the expression graph

    
TO LEARN:    
    Torch/TensorFlow

